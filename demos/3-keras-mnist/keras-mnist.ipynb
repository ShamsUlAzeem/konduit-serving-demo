{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running and MNIST dataset classifier through CUSTOM image endpoints\n",
    "---\n",
    "## Adding package to the classpath\n",
    "First of all we need to add the main package to the classpath so that the notebook can load all the necessary libraries from konduit-serving into the Jupyter notebook kernel.\n",
    "\n",
    "Classpaths can be considered similar to `site-packages` in the python ecosystem where each library that's to be imported to your code is loaded from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a16b309-1747-490b-b462-45f56ffea62f",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%classpath add jar ../../konduit.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import tensorflow as tf\n",
      "\n",
      "from keras.datasets import mnist\n",
      "\n",
      "\n",
      "tensorflow_version = tf.__version__\n",
      "print(tensorflow_version)\n",
      "\n",
      "# Load data\n",
      "train_data, test_data = mnist.load_data()\n",
      "x_train, y_train = train_data\n",
      "x_test, y_test = test_data\n",
      "\n",
      "# Normalize\n",
      "x_train = x_train / 255.0\n",
      "x_test = x_test / 255.0\n",
      "\n",
      "\n",
      "def get_model():\n",
      "    inputs = tf.keras.layers.Input(shape=(28, 28), name=\"input_layer\")\n",
      "    x = tf.keras.layers.Flatten()(inputs)\n",
      "    x = tf.keras.layers.Dense(200, activation=\"relu\")(x)\n",
      "    x = tf.keras.layers.Dense(100, activation=\"relu\")(x)\n",
      "    x = tf.keras.layers.Dense(60, activation=\"relu\")(x)\n",
      "    x = tf.keras.layers.Dense(30, activation=\"relu\")(x)\n",
      "    outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
      "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
      "    model.compile(\n",
      "        optimizer='sgd',\n",
      "        loss='sparse_categorical_crossentropy',\n",
      "        metrics=['accuracy']\n",
      "    )\n",
      "\n",
      "    return model\n",
      "\n",
      "\n",
      "def train(epochs=8):\n",
      "    model = get_model()\n",
      "    model.fit(x_train, y_train, epochs=epochs)\n",
      "\n",
      "    model.summary()\n",
      "\n",
      "    print(\"\\n\\n---\\n\"\n",
      "          \"Inputs: {}\".format(model.inputs))\n",
      "    print(\"Outputs: {}\\n---\".format(model.outputs))\n",
      "\n",
      "    return model\n",
      "\n",
      "\n",
      "train(8).save(\"keras.h5\", save_format=\"h5\")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "less train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ai.konduit.OCREndPoint"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package ai.konduit;\n",
    "\n",
    "import ai.konduit.serving.endpoint.Endpoint;\n",
    "import ai.konduit.serving.pipeline.api.data.Data;\n",
    "import ai.konduit.serving.pipeline.api.data.Image;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.Pipeline;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.PipelineExecutor;\n",
    "import ai.konduit.serving.pipeline.impl.format.JavaImageFactory;\n",
    "import ai.konduit.serving.pipeline.registry.ImageFactoryRegistry;\n",
    "import io.vertx.core.Handler;\n",
    "import io.vertx.core.http.HttpMethod;\n",
    "import io.vertx.ext.web.RoutingContext;\n",
    "\n",
    "import javax.imageio.ImageIO;\n",
    "import java.awt.image.BufferedImage;\n",
    "import java.io.File;\n",
    "import java.io.IOException;\n",
    "import java.util.ArrayList;\n",
    "import java.util.Arrays;\n",
    "import java.util.List;\n",
    "\n",
    "import ai.konduit.serving.pipeline.util.ObjectMappers;\n",
    "import ai.konduit.serving.pipeline.registry.NDArrayConverterRegistry;\n",
    "import ai.konduit.serving.data.nd4j.format.ND4JConverters;\n",
    "\n",
    "public class OCREndPoint implements Endpoint {\n",
    "\n",
    "    private PipelineExecutor pipelineExecutor;\n",
    "\n",
    "    public OCREndPoint(PipelineExecutor pipelineExecutor) { \n",
    "        this.pipelineExecutor = pipelineExecutor; \n",
    "        ImageFactoryRegistry.addFactory(new JavaImageFactory()); \n",
    "        NDArrayConverterRegistry.addConverter(new ND4JConverters.Nd4jToSerializedConverter()); \n",
    "        NDArrayConverterRegistry.addConverter(new ND4JConverters.SerializedToNd4jArrConverter());\n",
    "    }\n",
    "\n",
    "    public HttpMethod type() { return HttpMethod.POST; }\n",
    "\n",
    "    public String path() { return \"/infer\"; }\n",
    "\n",
    "    public List<String> consumes() { return Arrays.asList(\"application/octet-stream\",\"multipart/form-data\"); }\n",
    "\n",
    "    public List<String> produces() { return Arrays.asList(\"application/json\"); }\n",
    "\n",
    "    @Override\n",
    "    public Handler<RoutingContext> handler() {\n",
    "        return handler -> {\n",
    "            handler.vertx().executeBlocking(taskHandler -> {\n",
    "                Data image = Data.empty();\n",
    "                \n",
    "                try {\n",
    "                    image.put(\"image\",Image.create(ImageIO.read(new File(handler.fileUploads().iterator().next().uploadedFileName()))));\n",
    "                } catch (IOException e) {\n",
    "                    e.printStackTrace();\n",
    "                }\n",
    "\n",
    "                Data exec = pipelineExecutor.exec(image);\n",
    "                \n",
    "                handler.response().end(ObjectMappers.toJson(exec.getNDArray(\"output_layer\").getAs(float[].class)));\n",
    "                taskHandler.complete();\n",
    "            },resultHandler -> {\n",
    "                if(resultHandler.failed()) {\n",
    "                    if(resultHandler.cause() != null)\n",
    "                        if(handler.vertx().exceptionHandler() != null)\n",
    "                            handler.vertx().exceptionHandler().handle(resultHandler.cause());\n",
    "                        else {\n",
    "                            resultHandler.cause().printStackTrace();\n",
    "                        }\n",
    "                    else {\n",
    "                        System.err.println(\"Failed to process classification endpoint async task. Unknown cause.\");\n",
    "                    }\n",
    "                }\n",
    "            });\n",
    "\n",
    "        };\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ai.konduit.OCREndPoints"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package ai.konduit;\n",
    "\n",
    "import ai.konduit.serving.endpoint.Endpoint;\n",
    "import ai.konduit.serving.endpoint.HttpEndpoints;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.Pipeline;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.PipelineExecutor;\n",
    "\n",
    "import java.util.Arrays;\n",
    "import java.util.List;\n",
    "\n",
    "public class OCREndPoints implements HttpEndpoints {\n",
    "\n",
    "    @Override\n",
    "    public List<Endpoint> endpoints(Pipeline pipeline, PipelineExecutor pipelineExecutor) {\n",
    "        return Arrays.asList(new OCREndPoint(pipelineExecutor));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/beaker2817789069428804758/outDir\n",
      "/home/shams/PycharmProjects/konduit-serving-demo/konduit.jar\n",
      "Saved /tmp/beaker2817789069428804758/outDir:/home/shams/PycharmProjects/konduit-serving-demo/konduit.jar at: /home/shams/PycharmProjects/konduit-serving-demo/demos/3-keras-mnist/classpath\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.net.URLClassLoader;\n",
    "import java.net.URL;\n",
    "import java.io.File;\n",
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "\n",
    "import org.apache.commons.io.FileUtils;\n",
    "import java.io.IOException;\n",
    "\n",
    "import java.nio.charset.StandardCharsets;\n",
    "\n",
    "URL[] urls = ((URLClassLoader) Class.forName(\"ai.konduit.serving.vertx.config.InferenceConfiguration\").getClassLoader()).getURLs();\n",
    "List<String> classpaths = new ArrayList<>();\n",
    "\n",
    "for(URL url : urls) {\n",
    "    String singleClassPath = new File(url.toURI()).getAbsolutePath();\n",
    "    System.out.println(singleClassPath);\n",
    "    classpaths.add(singleClassPath);\n",
    "}\n",
    "\n",
    "try {\n",
    "    String output = String.join(File.pathSeparator, classpaths);\n",
    "    File classpathOutputPath = new File(\"classpath\");\n",
    "    FileUtils.writeStringToFile(new File(\"classpath\"), output, StandardCharsets.UTF_8);\n",
    "    System.out.format(\"Saved %s at: %s%n\", output, classpathOutputPath.getAbsolutePath());\n",
    "} catch (IOException e) {\n",
    "    e.printStackTrace();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting konduit server...\n",
      "Using classpath: /tmp/beaker2817789069428804758/outDir:/home/shams/PycharmProjects/konduit-serving-demo/konduit.jar\n",
      "INFO: Running command /home/shams/miniconda3/envs/beakerx/jre/bin/java -Dkonduit.logs.file.path=/home/shams/.konduit-serving/command_logs/keras-mnist.log -Dlogback.configurationFile=/tmp/logback-run_command_a5dd955cfcc44f5c.xml ai.konduit.serving.cli.launcher.KonduitServingLauncher run --instances 1 -s inference -c keras.json -Dserving.id=keras-mnist\n",
      "For server status, execute: 'java ai.konduit.serving.cli.launcher.KonduitServingLauncher list'\n",
      "For logs, execute: 'java ai.konduit.serving.cli.launcher.KonduitServingLauncher logs keras-mnist'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "java -cp $(cat classpath) ai.konduit.serving.cli.launcher.KonduitServingLauncher serve -id keras-mnist -c keras.json -rwm -b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Listing konduit servers...\n",
      "\n",
      "No konduit servers found.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "konduit list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11:16:49.986 [main] INFO  a.k.s.c.l.command.KonduitRunCommand - Processing configuration: /home/shams/PycharmProjects/konduit-serving-demo/demos/3-keras-mnist/keras.json\n",
      "11:16:49.992 [main] INFO  u.o.l.s.context.SysOutOverSLF4J - Replaced standard System.out and System.err PrintStreams with SLF4JPrintStreams\n",
      "11:16:49.994 [main] INFO  u.o.l.s.context.SysOutOverSLF4J - Redirected System.out and System.err to SLF4J for this context\n",
      "11:16:49.994 [main] INFO  a.k.s.c.l.command.KonduitRunCommand - Starting konduit server with an id of 'keras-mnist'\n",
      "11:16:50.243 [vert.x-worker-thread-0] INFO  a.k.s.p.registry.PipelineRegistry - Loaded 28 PipelineStepRunnerFactory instances\n",
      "11:16:50.442 [vert.x-worker-thread-0] INFO  org.nd4j.linalg.factory.Nd4jBackend - Loaded [JCublasBackend] backend\n",
      "11:16:50.442 [vert.x-worker-thread-0] ERROR o.n.common.config.ND4JClassLoading - Cannot find class [org.nd4j.linalg.jblas.JblasBackend] of provided class-loader.\n",
      "11:16:50.442 [vert.x-worker-thread-0] ERROR o.n.common.config.ND4JClassLoading - Cannot find class [org.canova.api.io.data.DoubleWritable] of provided class-loader.\n",
      "11:16:50.489 [vert.x-worker-thread-0] ERROR o.n.common.config.ND4JClassLoading - Cannot find class [org.nd4j.linalg.jblas.JblasBackend] of provided class-loader.\n",
      "11:16:50.490 [vert.x-worker-thread-0] ERROR o.n.common.config.ND4JClassLoading - Cannot find class [org.canova.api.io.data.DoubleWritable] of provided class-loader.\n",
      "11:16:52.231 [vert.x-worker-thread-0] INFO  org.nd4j.nativeblas.NativeOpsHolder - Number of threads used for linear algebra: 32\n",
      "11:16:52.245 [vert.x-worker-thread-0] INFO  o.n.l.a.o.e.DefaultOpExecutioner - Backend used: [CUDA]; OS: [Linux]\n",
      "11:16:52.246 [vert.x-worker-thread-0] INFO  o.n.l.a.o.e.DefaultOpExecutioner - Cores: [8]; Memory: [6.9GB];\n",
      "11:16:52.246 [vert.x-worker-thread-0] INFO  o.n.l.a.o.e.DefaultOpExecutioner - Blas vendor: [CUBLAS]\n",
      "11:16:52.250 [vert.x-worker-thread-0] INFO  o.nd4j.linalg.jcublas.JCublasBackend - ND4J CUDA build version: 11.0.167\n",
      "11:16:52.251 [vert.x-worker-thread-0] INFO  o.nd4j.linalg.jcublas.JCublasBackend - CUDA device 0: [GeForce RTX 2080 Ti]; cc: [7.5]; Total memory: [11554717696]\n",
      "11:16:52.251 [vert.x-worker-thread-0] INFO  o.nd4j.linalg.jcublas.JCublasBackend - CUDA device 1: [GeForce RTX 2080 Ti]; cc: [7.5]; Total memory: [11554717696]\n",
      "11:16:53.610 [vert.x-worker-thread-0] INFO  o.d.nn.graph.ComputationGraph - Starting ComputationGraph with WorkspaceModes set to [training: ENABLED; inference: ENABLED], cacheMode set to [NONE]\n",
      "11:16:53.631 [vert.x-worker-thread-0] INFO  a.k.s.m.d.step.DL4JRunner - \n",
      "11:16:53.631 [vert.x-worker-thread-0] INFO  a.k.s.v.verticle.InferenceVerticle - \n",
      "\n",
      "####################################################################\n",
      "#                                                                  #\n",
      "#    |  /   _ \\   \\ |  _ \\  |  | _ _| __ __|    |  /     |  /      #\n",
      "#    . <   (   | .  |  |  | |  |   |     |      . <      . <       #\n",
      "#   _|\\_\\ \\___/ _|\\_| ___/ \\__/  ___|   _|     _|\\_\\ _) _|\\_\\ _)   #\n",
      "#                                                                  #\n",
      "####################################################################\n",
      "\n",
      "11:16:53.631 [vert.x-worker-thread-0] INFO  a.k.s.v.verticle.InferenceVerticle - Pending server start, please wait...\n",
      "11:16:53.642 [vert.x-eventloop-thread-0] INFO  a.k.s.v.p.h.v.InferenceVerticleHttp - MetricsProvider implementation detected, adding endpoint /metrics\n",
      "11:16:53.748 [vert.x-eventloop-thread-0] INFO  a.k.s.v.verticle.InferenceVerticle - Writing inspection data at '/home/shams/.konduit-serving/servers/9969.data' with configuration: \n",
      "{\n",
      "  \"host\" : \"localhost\",\n",
      "  \"port\" : 37067,\n",
      "  \"protocol\" : \"HTTP\",\n",
      "  \"customEndpoints\" : [ \"ai.konduit.OCREndPoints\" ],\n",
      "  \"pipeline\" : {\n",
      "    \"steps\" : [ {\n",
      "      \"@type\" : \"IMAGE_TO_NDARRAY\",\n",
      "      \"config\" : {\n",
      "        \"height\" : 28,\n",
      "        \"width\" : 28,\n",
      "        \"dataType\" : \"FLOAT\",\n",
      "        \"includeMinibatchDim\" : true,\n",
      "        \"aspectRatioHandling\" : \"CENTER_CROP\",\n",
      "        \"format\" : \"CHANNELS_FIRST\",\n",
      "        \"channelLayout\" : \"GRAYSCALE\",\n",
      "        \"normalization\" : {\n",
      "          \"type\" : \"SCALE\"\n",
      "        },\n",
      "        \"listHandling\" : \"NONE\"\n",
      "      },\n",
      "      \"keys\" : [ \"image\" ],\n",
      "      \"outputNames\" : [ \"input_layer\" ],\n",
      "      \"keepOtherValues\" : true,\n",
      "      \"metadata\" : false,\n",
      "      \"metadataKey\" : \"@ImageToNDArrayStepMetadata\"\n",
      "    }, {\n",
      "      \"@type\" : \"LOGGING\",\n",
      "      \"logLevel\" : \"INFO\",\n",
      "      \"log\" : \"KEYS_AND_VALUES\"\n",
      "    }, {\n",
      "      \"@type\" : \"KERAS\",\n",
      "      \"modelUri\" : \"keras.h5\",\n",
      "      \"inputNames\" : [ \"input_layer\" ],\n",
      "      \"outputNames\" : [ \"output_layer\" ]\n",
      "    } ]\n",
      "  }\n",
      "}\n",
      "11:16:53.748 [vert.x-eventloop-thread-0] INFO  a.k.s.v.p.h.v.InferenceVerticleHttp - Inference HTTP server is listening on host: 'localhost'\n",
      "11:16:53.748 [vert.x-eventloop-thread-0] INFO  a.k.s.v.p.h.v.InferenceVerticleHttp - Inference HTTP server started on port 37067 with 3 pipeline steps\n",
      "11:17:06.864 [vert.x-worker-thread-3] INFO  a.k.s.p.i.step.logging.LoggingRunner - \"input_layer\": ai.konduit.serving.pipeline.impl.format.JavaNDArrays$SNDArray@3c201da4\n",
      "11:17:06.900 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - java.lang.RuntimeException: Op [mmul] execution failed\n",
      "11:17:06.900 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner.exec(CudaExecutioner.java:1907)\n",
      "11:17:06.900 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.nd4j.linalg.factory.Nd4j.exec(Nd4j.java:6567)\n",
      "11:17:06.900 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.nd4j.linalg.api.blas.impl.BaseLevel3.gemm(BaseLevel3.java:64)\n",
      "11:17:06.900 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.nd4j.linalg.api.ndarray.BaseNDArray.mmuli(BaseNDArray.java:3170)\n",
      "11:17:06.900 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.deeplearning4j.nn.layers.BaseLayer.preOutputWithPreNorm(BaseLayer.java:318)\n",
      "11:17:06.900 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.deeplearning4j.nn.layers.BaseLayer.preOutput(BaseLayer.java:291)\n",
      "11:17:06.900 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.deeplearning4j.nn.layers.BaseLayer.activate(BaseLayer.java:339)\n",
      "11:17:06.900 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.deeplearning4j.nn.graph.vertex.impl.LayerVertex.doForward(LayerVertex.java:111)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.deeplearning4j.nn.graph.ComputationGraph.outputOfLayersDetached(ComputationGraph.java:2439)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.deeplearning4j.nn.graph.ComputationGraph.output(ComputationGraph.java:1741)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.deeplearning4j.nn.graph.ComputationGraph.output(ComputationGraph.java:1697)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.deeplearning4j.nn.graph.ComputationGraph.output(ComputationGraph.java:1627)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat ai.konduit.serving.models.deeplearning4j.step.DL4JRunner.exec(DL4JRunner.java:248)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat ai.konduit.serving.pipeline.impl.pipeline.SequencePipelineExecutor.exec(SequencePipelineExecutor.java:85)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat ai.konduit.OCREndPoint.lambda$null$0(OCREndPoint.java:74)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat io.vertx.core.impl.ContextImpl.lambda$executeBlocking$2(ContextImpl.java:313)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat io.vertx.core.impl.TaskQueue.run(TaskQueue.java:76)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n",
      "11:17:06.901 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)\n",
      "11:17:06.902 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat java.lang.Thread.run(Thread.java:745)\n",
      "11:17:06.902 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - Caused by: java.lang.RuntimeException: MmulHelper::mmulMxM cuda failed !; Error code: [700]\n",
      "11:17:06.902 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner.exec(CudaExecutioner.java:2093)\n",
      "11:17:06.902 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \tat org.nd4j.linalg.jcublas.ops.executioner.CudaExecutioner.exec(CudaExecutioner.java:1886)\n",
      "11:17:06.902 [vert.x-eventloop-thread-0] ERROR java.lang.Throwable - \t... 20 more\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "konduit logs keras-mnist --lines 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><img src=\"test-image.jpg\" alt=\"title\"></html>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"test-image.jpg\" alt=\"title\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -s -H \"Content-Type: multipart/form-data\" -X POST -F 'image=@test-image.jpg' http://localhost:$(konduit inspect keras-mnist -q {port})/infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No konduit server exists with an id: 'keras-mnist'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "konduit stop keras-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "text/x-java",
   "file_extension": ".java",
   "mimetype": "",
   "name": "Java",
   "nbconverter_exporter": "",
   "version": "1.8.0_121"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
