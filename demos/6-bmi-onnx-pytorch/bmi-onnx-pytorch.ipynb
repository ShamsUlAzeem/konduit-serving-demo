{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87a6e1a-5283-4ee2-9d3a-10f64bb3b331",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%classpath add jar ../../konduit.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ai.konduit.serving.WebAppEndpoint"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package ai.konduit.serving;\n",
    "\n",
    "import ai.konduit.serving.endpoint.Endpoint;\n",
    "\n",
    "import io.vertx.core.Handler;\n",
    "import io.vertx.core.http.HttpMethod;\n",
    "import io.vertx.ext.web.RoutingContext;\n",
    "\n",
    "import javax.imageio.ImageIO;\n",
    "import java.awt.image.BufferedImage;\n",
    "import java.io.File;\n",
    "import java.io.IOException;\n",
    "import java.util.ArrayList;\n",
    "import java.util.Arrays;\n",
    "import java.util.List;\n",
    "\n",
    "import ai.konduit.serving.pipeline.api.pipeline.PipelineExecutor;\n",
    "\n",
    "import java.util.Timer;\n",
    "import java.util.TimerTask;\n",
    "import io.vertx.core.http.HttpHeaders;\n",
    "\n",
    "import java.io.File;\n",
    "\n",
    "import java.nio.charset.StandardCharsets;\n",
    "import org.apache.commons.io.FileUtils;\n",
    "import io.vertx.core.http.HttpHeaders;\n",
    "import io.vertx.ext.web.handler.StaticHandler;\n",
    "\n",
    "import org.slf4j.Logger;\n",
    "import org.slf4j.LoggerFactory;\n",
    "\n",
    "public class WebAppEndpoint implements Endpoint {\n",
    "    \n",
    "    final static Logger logger = LoggerFactory.getLogger(WebAppEndpoint.class);\n",
    "\n",
    "    private PipelineExecutor pipelineExecutor;\n",
    "\n",
    "    public WebAppEndpoint(PipelineExecutor pipelineExecutor) {\n",
    "        this.pipelineExecutor = pipelineExecutor;\n",
    "    }\n",
    "\n",
    "    public HttpMethod type() { return HttpMethod.GET; }\n",
    "\n",
    "    public String path() { return \"/web-app/*\"; }\n",
    "\n",
    "    public List<String> consumes() { return Arrays.asList(); }\n",
    "\n",
    "    public List<String> produces() { return Arrays.asList(\"application/html\"); }\n",
    "\n",
    "    @Override\n",
    "    public Handler<RoutingContext> handler() {\n",
    "        return handler -> { \n",
    "            try {\n",
    "                logger.info(new File(handler.request().path().substring(1)).getAbsolutePath());\n",
    "                handler.response().sendFile(new File(handler.request().path().substring(1)).getAbsolutePath()).end(); \n",
    "            } catch(Exception e) {\n",
    "                e.printStackTrace();\n",
    "                logger.error(\"Error: \", e);\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ai.konduit.serving.PrometheusEndpoint"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package ai.konduit.serving;\n",
    "\n",
    "import ai.konduit.serving.endpoint.Endpoint;\n",
    "\n",
    "import io.vertx.core.Handler;\n",
    "import io.vertx.core.http.HttpMethod;\n",
    "import io.vertx.ext.web.RoutingContext;\n",
    "\n",
    "import javax.imageio.ImageIO;\n",
    "import java.awt.image.BufferedImage;\n",
    "import java.io.File;\n",
    "import java.io.IOException;\n",
    "import java.util.ArrayList;\n",
    "import java.util.Arrays;\n",
    "import java.util.List;\n",
    "\n",
    "import ai.konduit.serving.pipeline.api.pipeline.PipelineExecutor;\n",
    "\n",
    "import io.micrometer.prometheus.PrometheusConfig;\n",
    "import io.micrometer.core.instrument.MeterRegistry;\n",
    "import io.micrometer.prometheus.PrometheusMeterRegistry;\n",
    "import io.micrometer.core.instrument.Counter;\n",
    "import io.micrometer.core.instrument.binder.jvm.JvmMemoryMetrics;\n",
    "import io.micrometer.core.instrument.binder.system.ProcessorMetrics;\n",
    "\n",
    "import java.util.Timer;\n",
    "import java.util.TimerTask;\n",
    "import io.vertx.core.http.HttpHeaders;\n",
    "\n",
    "public class PrometheusEndpoint implements Endpoint {\n",
    "\n",
    "    public static PrometheusMeterRegistry registry;\n",
    "    public static List<Counter> classCounterIncrement = new ArrayList();\n",
    "    public static List<String> labels = Arrays.asList(\"UnderWeight\", \"Normal_Range\", \"OverWeight\", \"Obese_ClassI\", \"Obese_ClassII\", \"Obese_ClassIII\", \"Obese_ClassIV\");\n",
    "    \n",
    "    static {\n",
    "        registry = new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);\n",
    "        \n",
    "        if (registry != null) {\n",
    "            System.out.println(\"Using metrics registry \" + registry.getClass().getName() + \" for inference\");\n",
    "            new JvmMemoryMetrics().bindTo(registry);\n",
    "            new ProcessorMetrics().bindTo(registry);\n",
    "            \n",
    "            // For scraping GPU metrics\n",
    "            try {\n",
    "                Class<?> gpuMetricsClass = Class.forName(\"ai.konduit.serving.gpu.GpuMetrics\");\n",
    "                Object instance = gpuMetricsClass.newInstance();\n",
    "                gpuMetricsClass.getMethod(\"bindTo\", MeterRegistry.class).invoke(instance, registry);\n",
    "            } catch(Exception exception) {\n",
    "                System.out.println(\"No GPU binaries found. Selecting and scraping only CPU metrics.\");\n",
    "            }\n",
    "            \n",
    "            Counter serverUpTimeCounter = registry.counter(\"bmi-onnx-pytorch.server.up.time\");\n",
    "            double increment = 5.0;\n",
    "            new Timer().schedule(new TimerTask() {\n",
    "                @Override\n",
    "                public void run() {\n",
    "                    serverUpTimeCounter.increment(increment);\n",
    "                }\n",
    "            }, 5000, ((int) increment) * 1000);\n",
    "            \n",
    "            \n",
    "            for (String label : labels) {\n",
    "                classCounterIncrement.add(Counter.builder(label)\n",
    "                        .description(\"Classification counts seen so far for class label: \" + label)\n",
    "                        .baseUnit(\"bmi-onnx-pytorch.classification.outcome\")\n",
    "                        .register(registry));\n",
    "            }\n",
    "        } else {\n",
    "            System.out.println(\"Not using metrics registry.\");\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    private PipelineExecutor pipelineExecutor;\n",
    "\n",
    "    public PrometheusEndpoint(PipelineExecutor pipelineExecutor) { \n",
    "        this.pipelineExecutor = pipelineExecutor;\n",
    "    }\n",
    "\n",
    "    public HttpMethod type() { return HttpMethod.GET; }\n",
    "\n",
    "    public String path() { return \"/server-metrics\"; }\n",
    "\n",
    "    public List<String> consumes() { return Arrays.asList(); }\n",
    "\n",
    "    public List<String> produces() { return Arrays.asList(\"text/plain; version=0.0.4; charset=utf-8\"); }\n",
    "\n",
    "    @Override\n",
    "    public Handler<RoutingContext> handler() {\n",
    "        return handler -> handler.response().putHeader(HttpHeaders.CONTENT_TYPE, \"text/plain; version=0.0.4; charset=utf-8\").end(registry.scrape());\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ai.konduit.serving.OCREndPoint"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package ai.konduit.serving;\n",
    "\n",
    "import ai.konduit.serving.endpoint.Endpoint;\n",
    "import ai.konduit.serving.pipeline.api.data.Data;\n",
    "import ai.konduit.serving.pipeline.api.data.Image;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.Pipeline;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.PipelineExecutor;\n",
    "import ai.konduit.serving.pipeline.impl.format.JavaImageFactory;\n",
    "import ai.konduit.serving.pipeline.registry.ImageFactoryRegistry;\n",
    "import io.vertx.core.Handler;\n",
    "import io.vertx.core.http.HttpMethod;\n",
    "import io.vertx.ext.web.RoutingContext;\n",
    "\n",
    "import javax.imageio.ImageIO;\n",
    "import java.awt.image.BufferedImage;\n",
    "import java.io.File;\n",
    "import java.io.IOException;\n",
    "import java.util.ArrayList;\n",
    "import java.util.Arrays;\n",
    "import java.util.List;\n",
    "\n",
    "import io.micrometer.core.instrument.Counter;\n",
    "import io.micrometer.core.instrument.Gauge;\n",
    "\n",
    "import ai.konduit.serving.pipeline.util.ObjectMappers;\n",
    "import ai.konduit.serving.pipeline.registry.NDArrayConverterRegistry;\n",
    "import ai.konduit.serving.data.nd4j.format.ND4JConverters;\n",
    "import io.vertx.core.json.JsonObject;\n",
    "\n",
    "public class OCREndPoint implements Endpoint {\n",
    "\n",
    "    private PipelineExecutor pipelineExecutor;\n",
    "\n",
    "    private double requestTime = -1.0;\n",
    "    private double pipelineTime = -1.0;\n",
    "\n",
    "    private Counter requestsHandled = PrometheusEndpoint.registry.counter(\"bmi-onnx-pytorch.requests.handled\");\n",
    "    private Gauge requestTimeGuage = Gauge.builder(\"bmi-onnx-pytorch.request.time.ms\", () -> requestTime).register(PrometheusEndpoint.registry);\n",
    "    private Gauge pipelineTimeGuage = Gauge.builder(\"bmi-onnx-pytorch.pipeline.time.ms\", () -> pipelineTime).register(PrometheusEndpoint.registry);\n",
    "    private Gauge requestThroughputGuage = Gauge.builder(\"bmi-onnx-pytorch.request.time.ms\", () -> 1 / requestTime * 1000).register(PrometheusEndpoint.registry);\n",
    "\n",
    "    public OCREndPoint(PipelineExecutor pipelineExecutor) { \n",
    "        this.pipelineExecutor = pipelineExecutor; \n",
    "        ImageFactoryRegistry.addFactory(new JavaImageFactory()); \n",
    "        NDArrayConverterRegistry.addConverter(new ND4JConverters.Nd4jToSerializedConverter()); \n",
    "        NDArrayConverterRegistry.addConverter(new ND4JConverters.SerializedToNd4jArrConverter());\n",
    "    }\n",
    "\n",
    "    public HttpMethod type() { return HttpMethod.POST; }\n",
    "\n",
    "    public String path() { return \"/infer\"; }\n",
    "\n",
    "    public List<String> consumes() { return Arrays.asList(\"application/octet-stream\",\"multipart/form-data\"); }\n",
    "\n",
    "    public List<String> produces() { return Arrays.asList(\"application/json\"); }\n",
    "\n",
    "    @Override\n",
    "    public Handler<RoutingContext> handler() {\n",
    "        return handler -> {\n",
    "            handler.vertx().executeBlocking(taskHandler -> {\n",
    "                double requestTimeStart = (double) System.currentTimeMillis();\n",
    "                Data image = Data.empty();\n",
    "                \n",
    "                try {\n",
    "                    image.put(\"image\",Image.create(ImageIO.read(new File(handler.fileUploads().iterator().next().uploadedFileName()))));\n",
    "                \n",
    "                    double pipelineTimeStart = (double) System.currentTimeMillis();\n",
    "                    Data exec = pipelineExecutor.exec(image);\n",
    "                    double pipelineTimeEnd = (double) System.currentTimeMillis();\n",
    "                    pipelineTime = pipelineTimeEnd - pipelineTimeStart;\n",
    "                    \n",
    "                    handler.response().end(ObjectMappers.toJson(exec));\n",
    "                    taskHandler.complete();\n",
    "\n",
    "                    requestsHandled.increment();\n",
    "\n",
    "                    String bmiClass = exec.getString(\"bmi_class\");\n",
    "                    int index = PrometheusEndpoint.labels.indexOf(bmiClass.replace(\" \", \"_\").trim());\n",
    "                    System.out.format(\"BMI CLASS: %s, for index %s\", bmiClass, index);\n",
    "                    if(index != -1) {\n",
    "                        PrometheusEndpoint.classCounterIncrement.get(index).increment();\n",
    "                    }\n",
    "                    \n",
    "                    double requestTimeEnd = (double) System.currentTimeMillis();\n",
    "                    requestTime = requestTimeEnd - requestTimeStart;\n",
    "                } catch (IOException e) {\n",
    "                    e.printStackTrace();\n",
    "                    handler.response().setStatusCode(500).end(new JsonObject().put(\"error\", e.getMessage()).encode());\n",
    "                    taskHandler.complete();\n",
    "                    \n",
    "                }\n",
    "            },resultHandler -> {\n",
    "                if(resultHandler.failed()) {\n",
    "                    if(resultHandler.cause() != null)\n",
    "                        if(handler.vertx().exceptionHandler() != null)\n",
    "                            handler.vertx().exceptionHandler().handle(resultHandler.cause());\n",
    "                        else {\n",
    "                            resultHandler.cause().printStackTrace();\n",
    "                        }\n",
    "                    else {\n",
    "                        System.err.println(\"Failed to process classification endpoint async task. Unknown cause.\");\n",
    "                    }\n",
    "                }\n",
    "            });\n",
    "\n",
    "        };\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ai.konduit.serving.OCREndPoints"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package ai.konduit.serving;\n",
    "\n",
    "import ai.konduit.serving.endpoint.Endpoint;\n",
    "import ai.konduit.serving.endpoint.HttpEndpoints;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.Pipeline;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.PipelineExecutor;\n",
    "\n",
    "import java.util.Arrays;\n",
    "import java.util.List;\n",
    "\n",
    "public class OCREndPoints implements HttpEndpoints {\n",
    "    \n",
    "    @Override\n",
    "    public List<Endpoint> endpoints(Pipeline pipeline, PipelineExecutor pipelineExecutor) {\n",
    "        return Arrays.asList(new OCREndPoint(pipelineExecutor), new PrometheusEndpoint(pipelineExecutor), new WebAppEndpoint(pipelineExecutor));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/beaker769589333114767497/outDir\n",
      "/root/konduit/konduit.jar\n",
      "\n",
      "-------------\n",
      "Saved content:\n",
      "-------------\n",
      "/tmp/beaker769589333114767497/outDir:/root/konduit/konduit.jar\n",
      "\tin file:\n",
      "/root/konduit/demos/6-bmi-onnx-pytorch/classpath\n",
      "-------------"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.net.URLClassLoader;\n",
    "import java.net.URL;\n",
    "import java.io.File;\n",
    "\n",
    "import java.util.ArrayList;\n",
    "import java.util.List;\n",
    "\n",
    "import org.apache.commons.io.FileUtils;\n",
    "import java.io.IOException;\n",
    "\n",
    "import java.nio.charset.StandardCharsets;\n",
    "\n",
    "URL[] urls = ((URLClassLoader) Class.forName(\"ai.konduit.serving.vertx.config.InferenceConfiguration\").getClassLoader()).getURLs();\n",
    "List<String> classpaths = new ArrayList<>();\n",
    "\n",
    "for(URL url : urls) {\n",
    "    String singleClassPath = new File(url.toURI()).getAbsolutePath();\n",
    "    System.out.println(singleClassPath);\n",
    "    classpaths.add(singleClassPath);\n",
    "}\n",
    "\n",
    "try {\n",
    "    String output = String.join(File.pathSeparator, classpaths);\n",
    "    File classpathOutputPath = new File(\"classpath\");\n",
    "    FileUtils.writeStringToFile(new File(\"classpath\"), output, StandardCharsets.UTF_8);\n",
    "    System.out.format(\"%n-------------%nSaved content:%n-------------%n%s%n\\tin file:%n%s%n-------------\", output, classpathOutputPath.getAbsolutePath());\n",
    "} catch (IOException e) {\n",
    "    e.printStackTrace();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nohup java -cp $(cat classpath) ai.konduit.serving.cli.launcher.KonduitServingLauncher serve -id bmi-onnx-pytorch -c bmi-onnx-pytorch.yaml -rwm &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:25:20.694 [main] INFO  a.k.s.c.l.command.KonduitRunCommand - Processing configuration: /root/konduit/demos/6-bmi-onnx-pytorch/bmi-onnx-pytorch.yaml\n",
      "16:25:20.708 [main] INFO  u.o.l.s.context.SysOutOverSLF4J - Replaced standard System.out and System.err PrintStreams with SLF4JPrintStreams\n",
      "16:25:20.710 [main] INFO  u.o.l.s.context.SysOutOverSLF4J - Redirected System.out and System.err to SLF4J for this context\n",
      "16:25:20.711 [main] INFO  a.k.s.c.l.command.KonduitRunCommand - Starting konduit server with an id of 'bmi-onnx-pytorch'\n",
      "16:25:21.466 [vert.x-worker-thread-0] INFO  a.k.s.p.registry.PipelineRegistry - Loaded 28 PipelineStepRunnerFactory instances\n",
      "16:25:22.058 [vert.x-worker-thread-0] INFO  a.k.serving.python.PythonRunner - Over riding python path :/root/miniconda/lib/python37.zip:/root/miniconda/lib/python3.7:/root/miniconda/lib/python3.7/lib-dynload:/root/miniconda/lib/python3.7/site-packages\n",
      "16:25:25.185 [vert.x-worker-thread-0] INFO  a.k.serving.python.PythonRunner - Resolving execution code from run_script.py\n",
      "16:25:25.188 [vert.x-worker-thread-0] INFO  a.k.serving.python.PythonRunner - Resolving import code from init_script.py\n",
      "16:25:25.189 [vert.x-worker-thread-0] INFO  org.nd4j.python4j.PythonGIL - Pre Gil State ensure for thread 16\n",
      "16:25:25.189 [vert.x-worker-thread-0] INFO  org.nd4j.python4j.PythonGIL - Thread 16 acquired GIL\n",
      "16:25:26.892 [vert.x-worker-thread-0] INFO  org.nd4j.python4j.PythonGIL - Releasing GIL on thread 16\n",
      "16:25:26.892 [vert.x-worker-thread-0] INFO  a.k.s.v.verticle.InferenceVerticle - \n",
      "\n",
      "####################################################################\n",
      "#                                                                  #\n",
      "#    |  /   _ \\   \\ |  _ \\  |  | _ _| __ __|    |  /     |  /      #\n",
      "#    . <   (   | .  |  |  | |  |   |     |      . <      . <       #\n",
      "#   _|\\_\\ \\___/ _|\\_| ___/ \\__/  ___|   _|     _|\\_\\ _) _|\\_\\ _)   #\n",
      "#                                                                  #\n",
      "####################################################################\n",
      "\n",
      "16:25:26.893 [vert.x-worker-thread-0] INFO  a.k.s.v.verticle.InferenceVerticle - Pending server start, please wait...\n",
      "16:25:26.923 [vert.x-eventloop-thread-0] INFO  a.k.s.v.p.h.v.InferenceVerticleHttp - MetricsProvider implementation detected, adding endpoint /metrics\n",
      "16:25:26.983 [vert.x-eventloop-thread-0] INFO  a.konduit.serving.PrometheusEndpoint - Using metrics registry io.micrometer.prometheus.PrometheusMeterRegistry for inference\n",
      "16:25:27.019 [vert.x-eventloop-thread-0] INFO  a.konduit.serving.PrometheusEndpoint - No GPU binaries found. Selecting and scraping only CPU metrics.\n",
      "16:25:27.256 [vert.x-eventloop-thread-0] INFO  a.k.s.v.verticle.InferenceVerticle - Writing inspection data at '/root/.konduit-serving/servers/162.data' with configuration: \n",
      "{\n",
      "  \"host\" : \"0.0.0.0\",\n",
      "  \"port\" : 9009,\n",
      "  \"useSsl\" : false,\n",
      "  \"protocol\" : \"HTTP\",\n",
      "  \"kafkaConfiguration\" : {\n",
      "    \"startHttpServerForKafka\" : true,\n",
      "    \"httpKafkaHost\" : \"localhost\",\n",
      "    \"httpKafkaPort\" : 0,\n",
      "    \"consumerTopicName\" : \"inference-in\",\n",
      "    \"consumerKeyDeserializerClass\" : \"io.vertx.kafka.client.serialization.JsonObjectDeserializer\",\n",
      "    \"consumerValueDeserializerClass\" : \"io.vertx.kafka.client.serialization.JsonObjectDeserializer\",\n",
      "    \"consumerGroupId\" : \"konduit-serving-consumer-group\",\n",
      "    \"consumerAutoOffsetReset\" : \"earliest\",\n",
      "    \"consumerAutoCommit\" : \"true\",\n",
      "    \"producerTopicName\" : \"inference-out\",\n",
      "    \"producerKeySerializerClass\" : \"io.vertx.kafka.client.serialization.JsonObjectSerializer\",\n",
      "    \"producerValueSerializerClass\" : \"io.vertx.kafka.client.serialization.JsonObjectSerializer\",\n",
      "    \"producerAcks\" : \"1\"\n",
      "  },\n",
      "  \"mqttConfiguration\" : { },\n",
      "  \"customEndpoints\" : [ \"ai.konduit.serving.OCREndPoints\" ],\n",
      "  \"pipeline\" : {\n",
      "    \"steps\" : [ {\n",
      "      \"@type\" : \"PYTHON\",\n",
      "      \"pythonConfig\" : {\n",
      "        \"pythonConfigType\" : \"CONDA\",\n",
      "        \"pythonPath\" : \"1\",\n",
      "        \"environmentName\" : \"base\",\n",
      "        \"appendType\" : \"BEFORE\",\n",
      "        \"pythonPathResolution\" : \"STATIC\",\n",
      "        \"pythonCodePath\" : \"run_script.py\",\n",
      "        \"pythonLibrariesPath\" : \":/root/miniconda/lib/python37.zip:/root/miniconda/lib/python3.7:/root/miniconda/lib/python3.7/lib-dynload:/root/miniconda/lib/python3.7/site-packages\",\n",
      "        \"importCodePath\" : \"init_script.py\",\n",
      "        \"pythonInputs\" : { },\n",
      "        \"pythonOutputs\" : { },\n",
      "        \"extraInputs\" : { },\n",
      "        \"returnAllInputs\" : false,\n",
      "        \"setupAndRun\" : false,\n",
      "        \"ioInputs\" : {\n",
      "          \"image\" : {\n",
      "            \"pythonType\" : \"image\",\n",
      "            \"secondaryType\" : \"NONE\",\n",
      "            \"type\" : \"IMAGE\"\n",
      "          }\n",
      "        },\n",
      "        \"ioOutputs\" : {\n",
      "          \"bmi_value\" : {\n",
      "            \"pythonType\" : \"float\",\n",
      "            \"secondaryType\" : \"NONE\",\n",
      "            \"type\" : \"DOUBLE\"\n",
      "          },\n",
      "          \"bmi_class\" : {\n",
      "            \"pythonType\" : \"str\",\n",
      "            \"secondaryType\" : \"NONE\",\n",
      "            \"type\" : \"STRING\"\n",
      "          },\n",
      "          \"boxes\" : {\n",
      "            \"pythonType\" : \"list\",\n",
      "            \"secondaryType\" : \"DOUBLE\",\n",
      "            \"type\" : \"LIST\"\n",
      "          }\n",
      "        },\n",
      "        \"jobSuffix\" : \"konduit_job\"\n",
      "      }\n",
      "    } ]\n",
      "  }\n",
      "}\n",
      "16:25:27.258 [vert.x-eventloop-thread-0] INFO  a.k.s.v.p.h.v.InferenceVerticleHttp - Inference HTTP server is listening on host: '0.0.0.0'\n",
      "16:25:27.258 [vert.x-eventloop-thread-0] INFO  a.k.s.v.p.h.v.InferenceVerticleHttp - Inference HTTP server started on port 9009 with 1 pipeline steps\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "konduit logs bmi-onnx-pytorch -l 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Listing konduit servers...\n",
      "\n",
      " #   | ID                             | TYPE       | URL                  | PID     | STATUS     \n",
      " 1   | bmi-onnx-pytorch               | inference  | 0.0.0.0:9009         | 162     | started    \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "konduit list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><img src=\"image_me.jpg\"/></html>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%html\n",
    "<img src=\"image_me.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "konduit inspect bmi-onnx-pytorch -q {port}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"bmi_value\" : 22.18,\n",
      "  \"bmi_class\" : \"Normal_Range\",\n",
      "  \"boxes\" : [ 447.0, 174.0, 636.0, 470.0 ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -s -H \"Content-Type: multipart/form-data\" -X POST -F \"image=@image_me.jpg\" http://localhost:$(konduit inspect bmi-onnx-pytorch -q {port})/infer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "The cell below also embeds the associated metrics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<div style=\"display: flex; justify-content: center; align-items: center; border: 1px solid black;\">\n",
       "    <iframe src=\"http://localhost:3000/d/lP_JcnHWz/pipeline-metrics?orgId=1&refresh=5s&kiosk&var-serverName=bmi_onnx_pytorch\" width=1500 height=1300>\n",
       "</div></html>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; align-items: center; border: 1px solid black;\">\n",
    "    <iframe src=\"http://localhost:3000/d/lP_JcnHWz/pipeline-metrics?orgId=1&refresh=5s&kiosk&var-serverName=bmi_onnx_pytorch\" width=1500 height=1300>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web application\n",
    "The cell below demonstrate the web application served by konduit-serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><div style=\"display: flex; justify-content: center; align-items: center; border: 1px solid black;\">\n",
       "    <iframe src=\"http://localhost:9009/web-app/index.html\" allow=\"camera;microphone\", width=1000 height=1000></iframe>\n",
       "</div></html>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%html\n",
    "<div style=\"display: flex; justify-content: center; align-items: center; border: 1px solid black;\">\n",
    "    <iframe src=\"http://localhost:9009/web-app/index.html\" allow=\"camera;microphone\", width=1000 height=1000></iframe>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping konduit server 'bmi-onnx-pytorch'\n",
      "Application 'bmi-onnx-pytorch' terminated with status 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "konduit stop bmi-onnx-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View metrics in Browser\n",
    "Visit: http://localhost:3000/d/lP_JcnHWz/pipeline-metrics?orgId=1&refresh=5s&kiosk&var-serverName=tensorflow_mnist to view metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "text/x-java",
   "file_extension": ".java",
   "mimetype": "",
   "name": "Java",
   "nbconverter_exporter": "",
   "version": "1.8.0_121"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
