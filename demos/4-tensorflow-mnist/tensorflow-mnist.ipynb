{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c864f61-23d8-4ea0-a994-141d2f125f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%classpath add jar ../../konduit.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No konduit server exists with an id: 'tensorflow-mnist'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "konduit stop tensorflow-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting konduit server...\n",
      "Using classpath: /root/konduit/bin/../konduit.jar\n",
      "INFO: Running command /root/miniconda/jre/bin/java -Dkonduit.logs.file.path=/root/.konduit-serving/command_logs/tensorflow-mnist.log -Dlogback.configurationFile=/tmp/logback-run_command_5fd1b7c309d448ea.xml -jar /root/konduit/bin/../konduit.jar run --instances 1 -s inference -c tensorflow.json -Dserving.id=tensorflow-mnist\n",
      "For server status, execute: 'konduit list'\n",
      "For logs, execute: 'konduit logs tensorflow-mnist'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "konduit serve -id tensorflow-mnist -c tensorflow.json -rwm --background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08:23:16.423 [main] INFO  a.k.s.c.l.command.KonduitRunCommand - Processing configuration: /root/konduit/demos/4-tensorflow-mnist/tensorflow.json\n",
      "08:23:16.429 [main] INFO  u.o.l.s.context.SysOutOverSLF4J - Replaced standard System.out and System.err PrintStreams with SLF4JPrintStreams\n",
      "08:23:16.430 [main] INFO  u.o.l.s.context.SysOutOverSLF4J - Redirected System.out and System.err to SLF4J for this context\n",
      "08:23:16.430 [main] INFO  a.k.s.c.l.command.KonduitRunCommand - Starting konduit server with an id of 'tensorflow-mnist'\n",
      "08:23:16.711 [vert.x-worker-thread-0] INFO  a.k.s.p.registry.PipelineRegistry - Loaded 28 PipelineStepRunnerFactory instances\n",
      "08:23:17.982 [vert.x-worker-thread-0] INFO  a.k.s.v.verticle.InferenceVerticle - \n",
      "\n",
      "####################################################################\n",
      "#                                                                  #\n",
      "#    |  /   _ \\   \\ |  _ \\  |  | _ _| __ __|    |  /     |  /      #\n",
      "#    . <   (   | .  |  |  | |  |   |     |      . <      . <       #\n",
      "#   _|\\_\\ \\___/ _|\\_| ___/ \\__/  ___|   _|     _|\\_\\ _) _|\\_\\ _)   #\n",
      "#                                                                  #\n",
      "####################################################################\n",
      "\n",
      "08:23:17.982 [vert.x-worker-thread-0] INFO  a.k.s.v.verticle.InferenceVerticle - Pending server start, please wait...\n",
      "08:23:18.004 [vert.x-eventloop-thread-0] INFO  a.k.s.v.p.h.v.InferenceVerticleHttp - MetricsProvider implementation detected, adding endpoint /metrics\n",
      "08:23:18.040 [vert.x-eventloop-thread-0] INFO  a.k.s.v.p.h.v.InferenceVerticleHttp - No GPU binaries found. Selecting and scraping only CPU metrics.\n",
      "08:23:18.145 [vert.x-eventloop-thread-0] INFO  a.k.s.v.verticle.InferenceVerticle - Writing inspection data at '/root/.konduit-serving/servers/7120.data' with configuration: \n",
      "{\n",
      "  \"host\" : \"0.0.0.0\",\n",
      "  \"port\" : 9008,\n",
      "  \"useSsl\" : false,\n",
      "  \"protocol\" : \"HTTP\",\n",
      "  \"staticContentRoot\" : \"static-content\",\n",
      "  \"staticContentUrl\" : \"/static-content\",\n",
      "  \"staticContentIndexPage\" : \"/index.html\",\n",
      "  \"kafkaConfiguration\" : {\n",
      "    \"startHttpServerForKafka\" : true,\n",
      "    \"httpKafkaHost\" : \"localhost\",\n",
      "    \"httpKafkaPort\" : 0,\n",
      "    \"consumerTopicName\" : \"inference-in\",\n",
      "    \"consumerKeyDeserializerClass\" : \"io.vertx.kafka.client.serialization.JsonObjectDeserializer\",\n",
      "    \"consumerValueDeserializerClass\" : \"io.vertx.kafka.client.serialization.JsonObjectDeserializer\",\n",
      "    \"consumerGroupId\" : \"konduit-serving-consumer-group\",\n",
      "    \"consumerAutoOffsetReset\" : \"earliest\",\n",
      "    \"consumerAutoCommit\" : \"true\",\n",
      "    \"producerTopicName\" : \"inference-out\",\n",
      "    \"producerKeySerializerClass\" : \"io.vertx.kafka.client.serialization.JsonObjectSerializer\",\n",
      "    \"producerValueSerializerClass\" : \"io.vertx.kafka.client.serialization.JsonObjectSerializer\",\n",
      "    \"producerAcks\" : \"1\"\n",
      "  },\n",
      "  \"mqttConfiguration\" : { },\n",
      "  \"customEndpoints\" : [ ],\n",
      "  \"pipeline\" : {\n",
      "    \"steps\" : [ {\n",
      "      \"@type\" : \"IMAGE_TO_NDARRAY\",\n",
      "      \"config\" : {\n",
      "        \"height\" : 28,\n",
      "        \"width\" : 28,\n",
      "        \"dataType\" : \"FLOAT\",\n",
      "        \"includeMinibatchDim\" : true,\n",
      "        \"aspectRatioHandling\" : \"CENTER_CROP\",\n",
      "        \"format\" : \"CHANNELS_FIRST\",\n",
      "        \"channelLayout\" : \"GRAYSCALE\",\n",
      "        \"normalization\" : {\n",
      "          \"type\" : \"SCALE\"\n",
      "        },\n",
      "        \"listHandling\" : \"NONE\"\n",
      "      },\n",
      "      \"keys\" : [ \"image\" ],\n",
      "      \"outputNames\" : [ \"input_layer\" ],\n",
      "      \"keepOtherValues\" : true,\n",
      "      \"metadata\" : false,\n",
      "      \"metadataKey\" : \"@ImageToNDArrayStepMetadata\"\n",
      "    }, {\n",
      "      \"@type\" : \"LOGGING\",\n",
      "      \"logLevel\" : \"INFO\",\n",
      "      \"log\" : \"KEYS_AND_VALUES\"\n",
      "    }, {\n",
      "      \"@type\" : \"ND4JTENSORFLOW\",\n",
      "      \"inputNames\" : [ \"input_layer\" ],\n",
      "      \"outputNames\" : [ \"output_layer/Softmax\" ],\n",
      "      \"constants\" : { },\n",
      "      \"modelUri\" : \"tensorflow.pb\"\n",
      "    }, {\n",
      "      \"@type\" : \"CLASSIFIER_OUTPUT\",\n",
      "      \"inputName\" : \"output_layer/Softmax\",\n",
      "      \"returnLabel\" : true,\n",
      "      \"returnIndex\" : true,\n",
      "      \"returnProb\" : true,\n",
      "      \"labelName\" : \"label\",\n",
      "      \"indexName\" : \"index\",\n",
      "      \"probName\" : \"prob\",\n",
      "      \"labels\" : [ \"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\" ],\n",
      "      \"allProbabilities\" : false\n",
      "    } ]\n",
      "  }\n",
      "}\n",
      "08:23:18.145 [vert.x-eventloop-thread-0] INFO  a.k.s.v.p.h.v.InferenceVerticleHttp - Inference HTTP server is listening on host: '0.0.0.0'\n",
      "08:23:18.145 [vert.x-eventloop-thread-0] INFO  a.k.s.v.p.h.v.InferenceVerticleHttp - Inference HTTP server started on port 9008 with 4 pipeline steps\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "konduit logs tensorflow-mnist -l 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>  <div style=\"display: flex; justify-content: center; align-items: center; border: 1px solid black;\">\n",
       "    <div style=\"display: inline-block; margin: 2px\">\n",
       "        <img src=\"test_files/test_input_number_0.png\"/>\n",
       "    </div>\n",
       "\n",
       "    <div style=\"display: inline-block; margin: 10px\">\n",
       "        <img src=\"test_files/test_input_number_1.png\"/>\n",
       "    </div>\n",
       "\n",
       "    <div style=\"display: inline-block; margin: 10px\">\n",
       "        <img src=\"test_files/test_input_number_2.png\"/>\n",
       "    </div>\n",
       "      \n",
       "    <div style=\"display: inline-block; margin: 10px\">\n",
       "        <img src=\"test_files/test_input_number_3.png\"/>\n",
       "    </div>\n",
       "      \n",
       "    <div style=\"display: inline-block; margin: 10px\">\n",
       "        <img src=\"test_files/test_input_number_4.png\"/>\n",
       "    </div>\n",
       "      \n",
       "    <div style=\"display: inline-block; margin: 10px\">\n",
       "        <img src=\"test_files/test_input_number_5.png\"/>\n",
       "    </div>\n",
       "\n",
       "    <div style=\"display: inline-block; margin: 10px\">\n",
       "        <img src=\"test_files/test_input_number_6.png\"/>\n",
       "    </div>\n",
       "\n",
       "    <div style=\"display: inline-block; margin: 10px\">\n",
       "        <img src=\"test_files/test_input_number_7.png\"/>\n",
       "    </div>\n",
       "      \n",
       "    <div style=\"display: inline-block; margin: 10px\">\n",
       "        <img src=\"test_files/test_input_number_8.png\"/>\n",
       "    </div>\n",
       "      \n",
       "    <div style=\"display: inline-block; margin: 10px\">\n",
       "        <img src=\"test_files/test_input_number_9.png\"/>\n",
       "    </div>\n",
       "      \n",
       "</div></html>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%html\n",
    "  <div style=\"display: flex; justify-content: center; align-items: center; border: 1px solid black;\">\n",
    "    <div style=\"display: inline-block; margin: 2px\">\n",
    "        <img src=\"test_files/test_input_number_0.png\"/>\n",
    "    </div>\n",
    "\n",
    "    <div style=\"display: inline-block; margin: 10px\">\n",
    "        <img src=\"test_files/test_input_number_1.png\"/>\n",
    "    </div>\n",
    "\n",
    "    <div style=\"display: inline-block; margin: 10px\">\n",
    "        <img src=\"test_files/test_input_number_2.png\"/>\n",
    "    </div>\n",
    "      \n",
    "    <div style=\"display: inline-block; margin: 10px\">\n",
    "        <img src=\"test_files/test_input_number_3.png\"/>\n",
    "    </div>\n",
    "      \n",
    "    <div style=\"display: inline-block; margin: 10px\">\n",
    "        <img src=\"test_files/test_input_number_4.png\"/>\n",
    "    </div>\n",
    "      \n",
    "    <div style=\"display: inline-block; margin: 10px\">\n",
    "        <img src=\"test_files/test_input_number_5.png\"/>\n",
    "    </div>\n",
    "\n",
    "    <div style=\"display: inline-block; margin: 10px\">\n",
    "        <img src=\"test_files/test_input_number_6.png\"/>\n",
    "    </div>\n",
    "\n",
    "    <div style=\"display: inline-block; margin: 10px\">\n",
    "        <img src=\"test_files/test_input_number_7.png\"/>\n",
    "    </div>\n",
    "      \n",
    "    <div style=\"display: inline-block; margin: 10px\">\n",
    "        <img src=\"test_files/test_input_number_8.png\"/>\n",
    "    </div>\n",
    "      \n",
    "    <div style=\"display: inline-block; margin: 10px\">\n",
    "        <img src=\"test_files/test_input_number_9.png\"/>\n",
    "    </div>\n",
    "      \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"output_layer/Softmax\" : [ [ 3.0811898E-7, 6.085964E-6, 1.1470697E-4, 1.5436264E-9, 0.0023717284, 1.7763212E-12, 6.587209E-11, 0.99487466, 4.904844E-11, 0.0026325122 ] ],\n",
      "  \"prob\" : 0.9948746562004089,\n",
      "  \"index\" : 7,\n",
      "  \"label\" : \"7\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "konduit predict tensorflow-mnist --input-type multipart \"image=@test_files/test_input_number_9.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 requests have been sent to the server. To view metrics, visit: http://localhost:3000/d/lP_JcnHWz/pipeline-metrics?orgId=1&refresh=5s&kiosk&var-serverName=tensorflow-mnist"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io.vertx.core.*;\n",
    "import io.vertx.ext.web.client.WebClient;\n",
    "import java.util.concurrent.TimeUnit;\n",
    "import io.vertx.ext.web.multipart.MultipartForm;\n",
    "\n",
    "Vertx vertx = Vertx.vertx(new VertxOptions().setMaxEventLoopExecuteTime(10).setMaxEventLoopExecuteTimeUnit(TimeUnit.SECONDS));\n",
    "    \n",
    "WebClient client = WebClient.create(vertx);\n",
    "\n",
    "int numberOfRequests = 1000;\n",
    "int numberOfClasses = 10;\n",
    "\n",
    "for(int j = 0; j < numberOfRequests; j++) {\n",
    "    for (int k = 0; k < numberOfClasses; k++) {\n",
    "        MultipartForm form = MultipartForm.create()\n",
    "                .attribute(\"imageDescription\", \"Image input\" + k)\n",
    "                .binaryFileUpload(\"image\", \"test_input_number_\" + k + \".png\", \"test_files/test_input_number_\" + k + \".png\", \"image/png\");\n",
    "\n",
    "        // Submit the form as a multipart form body\n",
    "        client.post(9008, \"localhost\", \"/predict\")\n",
    "            .putHeader(\"Accept\", \"application/json\")\n",
    "            .sendMultipartForm(form, ar -> {});\n",
    "    }\n",
    "}\n",
    "\n",
    "System.out.format(\"%s requests have been sent to the server. To view metrics, visit: http://localhost:3000/d/lP_JcnHWz/pipeline-metrics?orgId=1&refresh=5s&kiosk&var-serverName=tensorflow-mnist\", \n",
    "                  numberOfRequests * numberOfClasses);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "The cell below also embeds the associated metrics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<div style=\"display: flex; justify-content: center; align-items: center; border: 1px solid black;\">\n",
       "    <iframe src=\"http://localhost:3000/d/lP_JcnHWz/pipeline-metrics?orgId=1&refresh=5s&kiosk&var-serverName=tensorflow-mnist\" width=1500 height=1500>\n",
       "</div></html>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<div style=\"display: flex; justify-content: center; align-items: center; border: 1px solid black;\">\n",
    "    <iframe src=\"http://localhost:3000/d/lP_JcnHWz/pipeline-metrics?orgId=1&refresh=5s&kiosk&var-serverName=tensorflow-mnist\" width=1500 height=1500>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View metrics in Browser\n",
    "Visit: http://localhost:3000/d/lP_JcnHWz/pipeline-metrics?orgId=1&refresh=5s&kiosk&var-serverName=tensorflow-mnist to view metrics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "text/x-java",
   "file_extension": ".java",
   "mimetype": "",
   "name": "Java",
   "nbconverter_exporter": "",
   "version": "1.8.0_121"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
