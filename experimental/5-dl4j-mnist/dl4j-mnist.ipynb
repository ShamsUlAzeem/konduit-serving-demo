{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fc35e1-f2e4-4bbf-ad31-95aa308e97ca",
       "version_major": 2,
       "version_minor": 0
      },
      "method": "display_data"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%classpath add jar ../../konduit.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ai.konduit.OCREndPoint"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package ai.konduit;\n",
    "\n",
    "import ai.konduit.serving.endpoint.Endpoint;\n",
    "import ai.konduit.serving.pipeline.api.data.Data;\n",
    "import ai.konduit.serving.pipeline.api.data.Image;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.Pipeline;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.PipelineExecutor;\n",
    "import ai.konduit.serving.pipeline.impl.format.JavaImageFactory;\n",
    "import ai.konduit.serving.pipeline.registry.ImageFactoryRegistry;\n",
    "import io.vertx.core.Handler;\n",
    "import io.vertx.core.http.HttpMethod;\n",
    "import io.vertx.ext.web.RoutingContext;\n",
    "\n",
    "import javax.imageio.ImageIO;\n",
    "import java.awt.image.BufferedImage;\n",
    "import java.io.File;\n",
    "import java.io.IOException;\n",
    "import java.util.ArrayList;\n",
    "import java.util.Arrays;\n",
    "import java.util.List;\n",
    "\n",
    "public class OCREndPoint implements Endpoint {\n",
    "\n",
    "    private PipelineExecutor pipelineExecutor;\n",
    "\n",
    "    public OCREndPoint(PipelineExecutor pipelineExecutor) { this.pipelineExecutor = pipelineExecutor; ImageFactoryRegistry.addFactory(new JavaImageFactory()); }\n",
    "\n",
    "    public HttpMethod type() { return HttpMethod.POST; }\n",
    "\n",
    "    public String path() { return \"/infer\"; }\n",
    "\n",
    "    public List<String> consumes() { return Arrays.asList(\"application/octet-stream\",\"multipart/form-data\"); }\n",
    "\n",
    "    public List<String> produces() { return Arrays.asList(\"application/json\"); }\n",
    "\n",
    "    @Override\n",
    "    public Handler<RoutingContext> handler() {\n",
    "        return handler -> {\n",
    "            handler.vertx().executeBlocking(taskHandler -> {\n",
    "                Data image = Data.empty();\n",
    "                \n",
    "                try {\n",
    "                    image.put(\"image\",Image.create(ImageIO.read(new File(handler.fileUploads().iterator().next().uploadedFileName()))));\n",
    "                } catch (IOException e) {\n",
    "                    e.printStackTrace();\n",
    "                }\n",
    "\n",
    "                Data exec = pipelineExecutor.exec(image);\n",
    "                \n",
    "                handler.response().end(exec.toJson());\n",
    "                taskHandler.complete();\n",
    "            },resultHandler -> {\n",
    "                if(resultHandler.failed()) {\n",
    "                    if(resultHandler.cause() != null)\n",
    "                        if(handler.vertx().exceptionHandler() != null)\n",
    "                            handler.vertx().exceptionHandler().handle(resultHandler.cause());\n",
    "                        else {\n",
    "                            resultHandler.cause().printStackTrace();\n",
    "                        }\n",
    "                    else {\n",
    "                        System.err.println(\"Failed to process classification endpoint async task. Unknown cause.\");\n",
    "                    }\n",
    "                }\n",
    "            });\n",
    "\n",
    "        };\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ai.konduit.OCREndPoints"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "package ai.konduit;\n",
    "\n",
    "import ai.konduit.serving.endpoint.Endpoint;\n",
    "import ai.konduit.serving.endpoint.HttpEndpoints;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.Pipeline;\n",
    "import ai.konduit.serving.pipeline.api.pipeline.PipelineExecutor;\n",
    "\n",
    "import java.util.Arrays;\n",
    "import java.util.List;\n",
    "\n",
    "public class OCREndPoints implements HttpEndpoints {\n",
    "\n",
    "    @Override\n",
    "    public List<Endpoint> endpoints(Pipeline pipeline, PipelineExecutor pipelineExecutor) {\n",
    "        return Arrays.asList(new OCREndPoint(pipelineExecutor));\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "/* *****************************************************************************\n",
    " * Copyright (c) 2020 Konduit K.K.\n",
    " * Copyright (c) 2015-2019 Skymind, Inc.\n",
    " *\n",
    " * This program and the accompanying materials are made available under the\n",
    " * terms of the Apache License, Version 2.0 which is available at\n",
    " * https://www.apache.org/licenses/LICENSE-2.0.\n",
    " *\n",
    " * Unless required by applicable law or agreed to in writing, software\n",
    " * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n",
    " * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n",
    " * License for the specific language governing permissions and limitations\n",
    " * under the License.\n",
    " *\n",
    " * SPDX-License-Identifier: Apache-2.0\n",
    " ******************************************************************************/\n",
    "\n",
    "package org.deeplearning4j.examples.quickstart.modeling.feedforward.classification;\n",
    "\n",
    "\n",
    "import org.deeplearning4j.datasets.iterator.impl.MnistDataSetIterator;\n",
    "import org.deeplearning4j.nn.conf.MultiLayerConfiguration;\n",
    "import org.deeplearning4j.nn.conf.NeuralNetConfiguration;\n",
    "import org.deeplearning4j.nn.conf.layers.DenseLayer;\n",
    "import org.deeplearning4j.nn.conf.layers.OutputLayer;\n",
    "import org.deeplearning4j.nn.multilayer.MultiLayerNetwork;\n",
    "import org.deeplearning4j.nn.weights.WeightInit;\n",
    "import org.deeplearning4j.optimize.listeners.ScoreIterationListener;\n",
    "import org.nd4j.evaluation.classification.Evaluation;\n",
    "import org.nd4j.linalg.activations.Activation;\n",
    "import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;\n",
    "import org.nd4j.linalg.learning.config.Nadam;\n",
    "import org.nd4j.linalg.lossfunctions.LossFunctions.LossFunction;\n",
    "\n",
    "final int numRows = 28;\n",
    "final int numColumns = 28;\n",
    "int outputNum = 10; // number of output classes\n",
    "int batchSize = 64; // batch size for each epoch\n",
    "int rngSeed = 123; // random number seed for reproducibility\n",
    "int numEpochs = 15; // number of epochs to perform\n",
    "double rate = 0.0015; // learning rate\n",
    "\n",
    "//Get the DataSetIterators:\n",
    "DataSetIterator mnistTrain = new MnistDataSetIterator(batchSize, true, rngSeed);\n",
    "DataSetIterator mnistTest = new MnistDataSetIterator(batchSize, false, rngSeed);\n",
    "\n",
    "MultiLayerConfiguration conf = new NeuralNetConfiguration.Builder()\n",
    "    .seed(rngSeed) //include a random seed for reproducibility\n",
    "    .activation(Activation.RELU)\n",
    "    .weightInit(WeightInit.XAVIER)\n",
    "    .updater(new Nadam())\n",
    "    .l2(rate * 0.005) // regularize learning model\n",
    "    .list()\n",
    "    .layer(new DenseLayer.Builder() //create the first input layer.\n",
    "            .nIn(numRows * numColumns)\n",
    "            .nOut(500)\n",
    "            .build())\n",
    "    .layer(new DenseLayer.Builder() //create the second input layer\n",
    "            .nIn(500)\n",
    "            .nOut(100)\n",
    "            .build())\n",
    "    .layer(new OutputLayer.Builder(LossFunction.NEGATIVELOGLIKELIHOOD) //create hidden layer\n",
    "            .activation(Activation.SOFTMAX)\n",
    "            .nOut(outputNum)\n",
    "            .build())\n",
    "    .build();\n",
    "\n",
    "MultiLayerNetwork model = new MultiLayerNetwork(conf);\n",
    "model.init();\n",
    "model.setListeners(new ScoreIterationListener(5));  //print the score with every iteration\n",
    "\n",
    "model.fit(mnistTrain, numEpochs);\n",
    "Evaluation eval = model.evaluate(mnistTest);\n",
    "System.out.println(eval.stats());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shams\\AppData\\Local\\Temp\\beaker8021018875043833078\\outDir\n",
      "E:\\Demos\\nec\\konduit.jar\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "null"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.net.URLClassLoader;\n",
    "import java.net.URL;\n",
    "\n",
    "URL[] urls = ((URLClassLoader) Class.forName(\"ai.konduit.serving.vertx.config.InferenceConfiguration\").getClassLoader()).getURLs();\n",
    "\n",
    "for(URL url : urls) {\n",
    "    System.out.println(new java.io.File(url.toURI()));\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "alias konduit=bin/konduit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "java -cp C:\\Users\\shams\\AppData\\Local\\Temp\\beaker8021018875043833078\\outDir;../../konduit.jar ai.konduit.serving.cli.launcher.KonduitServingLauncher serve -id server -c tensorflow.json -rwm -b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "konduit logs server -l 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "curl -H \"Content-Type: multipart/form-data\" -X POST -F \"image=@images.jpg\" http://localhost:$(konduit inspect server -q {port})/infer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Java",
   "language": "java",
   "name": "java"
  },
  "language_info": {
   "codemirror_mode": "text/x-java",
   "file_extension": ".java",
   "mimetype": "",
   "name": "Java",
   "nbconverter_exporter": "",
   "version": "1.8.0_121"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
